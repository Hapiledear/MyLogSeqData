- 核心思想来自于Google发表的论文
- 顾名思义，将计算分为两类 Map 和 Reduce
	- Map
		- 以一条记录为单位做映射，1进N出
		- 映射，变换，过滤2
	- Reduce
		- 以一组(多条记录)为单位做计算
		- 依赖 key:value 这种数据格式，而这种结构是Map阶段的输出结果
		- 分解，缩小，归纳
		- 输出的结果称为 partition 分区
- Split 切片
	- 默认情况下，等价于 [[HDFS]] 中的Block块,是它在程序中的抽象概念
	- 好处
		- 与物理块解耦，可以控制输入数据单元的大小
		- 可以控制并行度
		- 物理层的Block块会把一行数据切割开，它们将在切片中复原
- MapReduce过程
collapsed:: true
	- ![image.png](../assets/image_1648367835052_0.png)
- Map and Reduce Task
collapsed:: true
	- ![image.png](../assets/image_1648367900422_0.png)
	- Map Task
	  id:: 624e99ec-7cd9-4511-8995-ae6e8ff3a27c
		- 对记录进行格式化，以记录为单位调用map方法
		- 将记录映射成k,v kv会参与分区计算，通过key计算出分区p 最终结构其实是 k,v,p
		- 输出的中间数据，以一个文件的形式，存放在本地的系统中
		- 内存缓冲区 [[溢写]] 磁盘时，做一个 [[二次排序]] 。达到分区有序，且分区内key有序
			- 未来,相同的一组key会相邻在一起
	- Reduce Task
	  id:: 624e99ec-4fdb-4f08-93bf-94aae0682b18
		- 首先进行 [[归并排序]] ，排序结果可以直接接入Reduce方法
			- 通过 [[迭代器模式]] 的支持
		-
- MapTask 源码
	- run方法中
		- if 没有reduce方法，map占1 else map占 0.666 sort 占0.333
		- 通过客户端传过来的Job和其中的config 来创建 jobContext,mapper,input[inputFormat,split],output,mapperContext[cconfig,reader,writer,split]
		- try方法块中
			- input.initialize
				- LineRecordReader中处理被切割开的单词的方式
					- 每个切片(除了第一个切片)都让出第一行，从第二行开始读取
					- 相应的，每个切片的结束都需要多读一行
			- mapper.run(mapperContext)
				- nextKeyValue()方法 最终调用的是LineRecordReader.nextKeyValue()
			- output.write
				- NewOutputColector中
					- 有多少个reduce task 就有多少个分区
				- 最终输出到MapOutputBuffer中
					- init方法中
						- 溢写(spilper)的大小为0.8
						- sort大小为100m
						-
					-
	-